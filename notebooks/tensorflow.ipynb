{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 13:47:44.462986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from keras import losses\n",
    "from datasets import load_dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 13:47:49.679473: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-05-23 13:47:49.679682: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:134] retrieving CUDA diagnostic information for host: bc7a507b51ff\n",
      "2024-05-23 13:47:49.679719: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:141] hostname: bc7a507b51ff\n",
      "2024-05-23 13:47:49.680135: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:165] libcuda reported version is: 545.23.6\n",
      "2024-05-23 13:47:49.680206: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:169] kernel reported version is: 535.171.4\n",
      "2024-05-23 13:47:49.680224: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:251] kernel version 535.171.4 does not match DSO version 545.23.6 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "#chekc if GPU is available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available:\", physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 86914\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 15338\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/processed\"\n",
    "dataset = load_dataset(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Malec skóroval padáčkem jako Poborský. Zase střílí góly až v play off V\\xa0základní části hokejové extraligy nic, tam brněnský obránce Tomáš\\xa0Malec\\xa0góly nedává. Naposled se během dvaapadesátikolového maratonu trefil v\\xa0sezoně 2013/14. V\\xa0play off je to u něho o něčem jiném, tam se slovenský poctivec s\\xa0číslem 71 prosazuje každoročně. Povedlo se mu to i letos. Gólem vteřinu před koncem prvního finále v\\xa0Liberci poslal Kometu do vedení na 3:2, navíc to byl gól hodně kuriózní.', 'label': 13}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#chek if datasets are splited correctly\n",
    "train_label = dataset['train']['label']\n",
    "test_label = dataset['test']['label']\n",
    "\n",
    "unique_train_label = list(set(train_label))\n",
    "unique_test_label = list(set(test_label))\n",
    "\n",
    "# Sort the unique values\n",
    "train_set_sorted = sorted(unique_train_label)\n",
    "test_set_sorted = sorted(unique_test_label)\n",
    "\n",
    "# Check if both contain the same elements\n",
    "are_elements_same = (train_set_sorted == test_set_sorted)\n",
    "print(train_set_sorted)\n",
    "print(test_set_sorted)\n",
    "print(are_elements_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max lenght of train sequence: 337\n",
      "Max lenght of test sequence: 337\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_get_lengths(examples):\n",
    "    tokenized_examples = tokenizer(examples['text'], truncation=False, padding=False)\n",
    "    return {'length': [len(tokens) for tokens in tokenized_examples['input_ids']]}\n",
    "\n",
    "# Použití funkce na celý dataset\n",
    "measure = dataset.map(tokenize_and_get_lengths, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Zjištění maximální délky\n",
    "max_seq_train_length = max(measure['train']['length'])\n",
    "print(f'Max lenght of train sequence: {max_seq_train_length}')\n",
    "\n",
    "max_seq_test_length = max(measure['test']['length'])\n",
    "print(f'Max lenght of test sequence: {max_seq_train_length}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for my dataset is max lenght of sequence: 337\n",
    "max_seq_length = 512\n",
    "encodings = tokenizer(dataset['train']['text'], max_length=max_seq_length,truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.constant(encodings['input_ids'])\n",
    "attention_mask = tf.constant(encodings['attention_mask'])\n",
    "labels = tf.constant(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.constant(encodings['input_ids']).shape)\n",
    "print(tf.constant(encodings['attention_mask']).shape)\n",
    "print(tf.constant(dataset['train']['label']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(input_ids, attention_mask, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        },\n",
    "        labels\n",
    "    ))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classic stetup\n",
    "batch_size = 32\n",
    "train_dataset = create_tf_dataset(input_ids, attention_mask, labels)\n",
    "train_dataset = train_dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "EPOCHS = 3\n",
    "count_of_categories =24\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=count_of_categories)\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "model.fit(train_dataset, batch_size=batch_size, epochs=EPOCHS,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item = dataset['test'][10]\n",
    "print(test_item['text'])\n",
    "print(test_item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "inputs = tokenizer(test_item['text'], truncation=False, padding=False, return_tensors='tf')\n",
    "outputs = model(inputs)\n",
    "predicted_class_idx = tf.argmax(outputs.logits, axis=-1).numpy()[0]\n",
    "print(predicted_class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"../my_model\"\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
