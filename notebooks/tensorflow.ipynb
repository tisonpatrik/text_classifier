{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import activations, losses\n",
    "from datasets import load_dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available:\", physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/processed\"\n",
    "dataset = load_dataset(path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_text = dataset['train']['encoded_text']\n",
    "test_encoded_text = dataset['test']['encoded_text']\n",
    "\n",
    "unique_train_encoded_text = list(set(train_encoded_text))\n",
    "unique_test_encoded_text = list(set(test_encoded_text))\n",
    "\n",
    "# Sort the unique values\n",
    "train_set_sorted = sorted(unique_train_encoded_text)\n",
    "test_set_sorted = sorted(unique_test_encoded_text)\n",
    "\n",
    "# Check if both contain the same elements\n",
    "are_elements_same = (train_set_sorted == test_set_sorted)\n",
    "print(train_set_sorted)\n",
    "print(test_set_sorted)\n",
    "print(are_elements_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_get_lengths(examples):\n",
    "    tokenized_examples = tokenizer(examples['text'], truncation=False, padding=False)\n",
    "    return {'length': [len(tokens) for tokens in tokenized_examples['input_ids']]}\n",
    "\n",
    "# Použití funkce na celý dataset\n",
    "measure = dataset.map(tokenize_and_get_lengths, batched=True, remove_columns=['text'])\n",
    "\n",
    "# Zjištění maximální délky\n",
    "max_seq_length = max(measure['train']['length'])\n",
    "print(f'Max lenght of sequence: {max_seq_length}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "encodings = tokenizer(dataset['train']['text'], max_length=max_seq_length,truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.constant(encodings['input_ids'])\n",
    "attention_mask = tf.constant(encodings['attention_mask'])\n",
    "labels = tf.constant(dataset['train']['encoded_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.constant(encodings['input_ids']).shape)\n",
    "print(tf.constant(encodings['attention_mask']).shape)\n",
    "print(tf.constant(dataset['train']['encoded_text']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(input_ids, attention_mask, labels):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        },\n",
    "        labels\n",
    "    ))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = create_tf_dataset(input_ids, attention_mask, labels)\n",
    "train_dataset = train_dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "count_of_categories =24\n",
    "\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=count_of_categories)\n",
    "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "model.fit(train_dataset, batch_size=batch_size, epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
